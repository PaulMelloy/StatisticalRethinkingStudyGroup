---
title: "Week4_Chapter3"
author: "P. Melloy"
date: "25/08/2020"
output: html_document
---
```{r message=FALSE, warning=FALSE}
library(rethinking)
library(dplyr)
```

```{r}
Pr_Positive_Vampire <- 0.95
Pr_Positive_Mortal <- 0.01
Pr_Vampire <- 0.001
Pr_Positive <- Pr_Positive_Vampire * Pr_Vampire +
Pr_Positive_Mortal * ( 1 - Pr_Vampire )
( Pr_Vampire_Positive <- Pr_Positive_Vampire*Pr_Vampire / Pr_Positive )
```

```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 )
prob_p <- rep( 1 , 1000 )
prob_data <- dbinom( 6 , size=9 , prob=p_grid )
posterior <- prob_data * prob_p
posterior <- posterior / sum(posterior)
```


```{r}
samples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )
plot(samples)
```

# Exercises  
## Easy
**Easy.** These problems use the samples from the posterior distribution for the globe tossing example.
This code will give you a specific set of samples, so that you can check your answers exactly

```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 )
prior <- rep( 1 , 1000 )
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)
set.seed(100)
samples1 <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )
```

Use the values in samples to answer the questions that follow.
3E1. How much posterior probability lies below p = 0.2?
```{r}
sum(samples1 < 0.2)/length(samples1)*100
sum(samples1 < 0.2)/1e4*100
```

3E2. How much posterior probability lies above p = 0.8?  
```{r}
sum(samples1 > 0.8)/length(samples1) * 100
```

3E3. How much posterior probability lies between p = 0.2 and p = 0.8?  
```{r}
sum(samples1[samples1 < 0.8 & 
       samples1 > 0.2])/length(samples1)
```

3E4. 20% of the posterior probability lies below which value of p?
```{r}
quantile(samples1,0.2)
1 - quantile(samples1,0.2)
```


3E5. 20% of the posterior probability lies above which value of p?
```{r}
quantile(samples1,0.8)
E5 <- quantile(samples1,c(0.8, 1))
E5[2]-E5[1]
```



3E6. Which values of p contain the narrowest interval equal to 66% of the posterior probability?
```{r}
HPDI(samples1, prob = 0.66)
```

3E7. Which values of p contain 66% of the posterior probability, assuming equal posterior probability
both below and above the interval?  
```{r}
PI(samples1, prob = 0.66)
```



## Medium.  
### 3M1.  
Suppose the globe tossing data had turned out to be 8 water in 15 tosses. Construct the posterior
distribution, using grid approximation. Use the same flat prior as before.

```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 ) # create a grid of all the possibilities
prior <- rep( 1 , 1000 )  # a prior which states all probabilities are equally likely
likelihood <- dbinom( 8 , size=15 , prob=p_grid ) # What is the likiehood of 8 outcomes from 15 samples given a probability of p_grid
posterior <- likelihood * prior  # "add" the likihood to the prior to find the posterier
posterior <- posterior / sum(posterior) # normalise the posterior
set.seed(100)
samples2 <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE ) # sample from all the possible probabilities 10k times with the probabilities in our posterier
```


### 3M2.  
Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate
the 90% HPDI for p.  
*-HPDI finds the most probable outcomes, and results in intervals which are shorter than any other intervals*
```{r}
HPDI(samples2, 0.9)
```


### 3M3.  
Construct a posterior predictive check for this model and data. This means simulate the distribution
of samples, averaging over the posterior uncertainty in p. What is the probability of observing
8 water in 15 tosses?
```{r}
w <- rbinom(n = 1e5,        # randomly sample 10k samples
            size = 15,      # that have 15 trials
            prob = samples2) # with the probability of our sampled posterior

summary(w)                  # summarise the number of outcomes to trials there were
simplehist(w)               # show the number of outcomes to trials in a histogram

prob_8_15unif <-                # What is the probability of 8 water (outcomes) from 15 tosses (trials)
   sum(w == 8)/length(w)    # sum the number of of w which equal 8 and divide by the total number of w's

paste(round(100*prob_8_15unif, 4),"%")    # show as a percentage
```


### 3M4. 
Using the posterior distribution constructed from the new (8/15) data, now calculate the probability
of observing 6 water in 9 tosses.

```{r}
w <- rbinom(n = 1e5,        # randomly sample 10k samples
            size = 9,       # that have 9 trials
            prob = samples2) # with the probability of our sampled posterior

summary(w)                  # summarise the number of outcomes to trials there were
simplehist(w)               # show the number of outcomes to trials in a histogram

prob_6_9unif <-                # What is the probability of 8 water (outcomes) from 15 tosses (trials)
   sum(w == 6)/length(w)    # sum the number of of w which equal 8 and divide by the total number of w's

paste(round(100*prob_6_9unif, 4),"%")    # show as a percentage
```

### 3M5.  
Start over at 3M1, but now use a prior that is zero below p = 0.5 and a constant above p = 0.5.
This corresponds to prior information that a majority of the Earth’s surface is water. Repeat each
problem above and compare the inferences. What difference does the better prior make? If it helps,
compare inferences (using both priors) to the true value p = 0.7.

```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 ) # create a grid of all the possibilities
prior <- as.numeric(p_grid > 0.5)  # a prior which states for the probabilities in p_grid, one above 0.5 are equally likely, while below ore impossible
likelihood <- dbinom( 8 , size=15 , prob=p_grid ) # What is the likelihood of 8 outcomes from 15 samples given a probability of p_grid
posterior <- likelihood * prior  # "add" the likelihood to the prior to find the posterior
posterior <- posterior / sum(posterior) # normalise the posterior
set.seed(100)
samples3 <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE ) # sample from all the possible probabilities 10k times with the probabilities in our posterior
```

Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate
the 90% HPDI for p.  

```{r}
HPDI(samples3, 0.9)
```

Construct a posterior predictive check for this model and data. This means simulate the distribution
of samples, averaging over the posterior uncertainty in p. What is the probability of observing
8 water in 15 tosses?  

```{r}
w <- rbinom(n = 1e5,        # randomly sample 10k samples
            size = 15,      # that have 15 trials
            prob = samples3) # with the probability of our sampled posterior

summary(w)                  # summarise the number of outcomes to trials there were
simplehist(w)               # show the number of outcomes to trials in a histogram

prob_8_15 <-                # What is the probability of 8 water (outcomes) from 15 tosses (trials)
   sum(w == 8)/length(w)    # sum the number of of w which equal 8 and divide by the total number of w's

paste(round(100*prob_8_15, 4),"%")    # show as a percentage
```

Using the posterior distribution constructed from the new (8/15) data, now calculate the probability
of observing 6 water in 9 tosses.  
```{r}
w <- rbinom(n = 1e5,        # randomly sample 10k samples
            size = 9,       # that have 9 trials
            prob = samples3) # with the probability of our sampled posterior

summary(w)                  # summarise the number of outcomes to trials there were
simplehist(w)               # show the number of outcomes to trials in a histogram

prob_6_9 <-                # What is the probability of 6 water (outcomes) from 9 tosses (trials)
   sum(w == 6)/length(w)    # sum the number of of w which equal 8 and divide by the total number of w's

paste(round(100*prob_6_9, 4),"%")    # show as a percentage
```

**uniform prior**
```{r}
paste(round(100*prob_8_15unif, 4),"%") 
paste(round(100*prob_6_9unif, 4),"%") 
```

**prior eliminating the probabilities below 0.5**
```{r}
paste(round(100*prob_8_15, 4),"%") 
paste(round(100*prob_6_9, 4),"%") 
```



3M6. Suppose you want to estimate the Earth’s proportion of water very precisely. Specifically, you
want the 99% percentile interval of the posterior distribution of p to be only 0.05 wide. This means
the distance between the upper and lower bound of the interval should be 0.05. How many times will
you have to toss the globe to do this?

*We could define better priors which would shorten this, however we will write a loop to show estimate the brute force method.*
*here we will assume flat prior, and the true proportion of water is 0.7*
```{r}
for(i in 1:1000){
if(i == 1){
   p_grid <- seq( from=0 , to=1 , length.out=1000 ) # create a grid of all the possibilities
   prior <- rep( 1 , 1000 )  # a prior which states all probabilities are equally likely
   tosses <- 10 # each iteration will toss the globe ten times to define a posterior, then this will be added to the prior
   total_tosses <- 0
   hdpi <- vector(mode = "list", length = 1000)
posteriors <- vector(mode = "list", length = 1000)
hdpinterval <- vector()
}
# Given the uncertainty of throwing the globe and it landing on water we will sample for the likelihood calculations
# we will start at 1000 tosses

n_water <- rbinom(1,size = tosses,prob = 0.7)

likelihood <- dbinom( n_water , size= tosses , prob=p_grid ) # What is the likiehood of 8 outcomes from 15 samples given a probability of p_grid
posterior <- likelihood * prior  # "add" the likihood to the prior to find the posterier
posterior <- posterior / sum(posterior) # normalise the posterior

samplesIt <- sample(p_grid , prob=posterior , size=1e4 , replace=TRUE ) # sample from all the possible probabilities 10k times with the probabilities

total_tosses <- tosses + total_tosses 
hdpi[[i]] <- HPDI(samplesIt, prob = 0.99)
hdpinterval <- c(hdpinterval, hdpi[[i]][2] - hdpi[[i]][1])
posteriors[[i]] <- posterior
prior <- posterior
if(hdpinterval[i] < 0.05){break}
}

plot(hdpinterval, )
for(j in seq(from =100, to = total_tosses, by =100)/10){

   if(j == 10){plot(x = p_grid, y = posteriors[[j]], ylim = c(0,0.04))}
   else{lines(x = p_grid, y = posteriors[[j]], col = abs(j/10))}
}
paste("This code, with a uniform prior, needed", total_tosses, "tosses of the globe until the HPDI was aprrox 0.05")

```
*width of priors and the parameter inside rbinom for variance could influence how many tosses we calculate*


*here we will assume informed prior (water covers more than half the globe), and the true proportion of water is 0.7*
```{r}
for(i in 1:1000){
if(i == 1){
   p_grid <- seq( from=0 , to=1 , length.out=1000 ) # create a grid of all the possibilities
   prior <- as.numeric(p_grid > 0.5)
   tosses <- 10 # each iteration will toss the globe ten times to define a posterior, then this will be added to the prior
   total_tosses <- 0
   hdpi <- vector(mode = "list", length = 1000)
posteriors <- vector(mode = "list", length = 1000)
hdpinterval <- vector()
}
# Given the uncertainty of throwing the globe and it landing on water we will sample for the likelihood calculations
# we will start at 1000 tosses

n_water <- rbinom(1,size = tosses,prob = 0.7)

likelihood <- dbinom( n_water , size= tosses , prob=p_grid ) # What is the likiehood of 8 outcomes from 15 samples given a probability of p_grid
posterior <- likelihood * prior  # "add" the likihood to the prior to find the posterier
posterior <- posterior / sum(posterior) # normalise the posterior

samplesIt <- sample(p_grid , prob=posterior , size=1e4 , replace=TRUE ) # sample from all the possible probabilities 10k times with the probabilities

total_tosses <- tosses + total_tosses 
hdpi[[i]] <- HPDI(samplesIt, prob = 0.99)
hdpinterval <- c(hdpinterval, hdpi[[i]][2] - hdpi[[i]][1])
posteriors[[i]] <- posterior
prior <- posterior
if(hdpinterval[i] < 0.05){break}
}

plot(hdpinterval, )

for(j in seq(from =100, to = total_tosses, by =100)/10){

   if(j == 10){plot(x = p_grid, y = posteriors[[j]], ylim = c(0,0.04))}
   else{lines(x = p_grid, y = posteriors[[j]], col = abs(j/10))}
}
paste("This code, with an informed prior needed", total_tosses, "tosses of the globe until the HPDI was aprrox 0.05")


```





## Hard.
Introduction. The practice problems here all use the data below. These data indicate the gender
(male=1, female=0) of officially reported first and second born children in 100 two-child families.
```{r birthData}
birth1 <- c(1,0,0,0,1,1,0,1,0,1,0,0,1,1,0,1,1,0,0,0,1,0,0,0,1,0,
0,0,0,1,1,1,0,1,0,1,1,1,0,1,0,1,1,0,1,0,0,1,1,0,1,0,0,0,0,0,0,0,
1,1,0,1,0,0,1,0,0,0,1,0,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,0,1,1,0,
1,0,1,1,1,0,1,1,1,1)
birth2 <- c(0,1,0,1,0,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,0,
1,1,1,0,1,1,1,0,1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,
1,1,1,0,1,1,0,1,1,0,1,1,1,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1,0,0,1,1,
0,0,0,1,1,1,0,0,0,0)
```

So for example, the first family in the data reported a boy (1) and then a girl (0). The second family
reported a girl (0) and then a boy (1). The third family reported two girls. You can load these two
vectors into R’s memory by typing:
```{r HardData}
library(rethinking)
data(homeworkch3)
```

Use these vectors as data. So for example to compute the total number of boys born across all of these
births, you could use:

```{r}
sum(birth1) + sum(birth2)
```

**3H1.** 
Using grid approximation, compute the posterior distribution for the probability of a birth
being a boy. Assume a uniform prior probability. Which parameter value maximizes the posterior
probability?

```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 ) # create a grid of all the possibilities
prior <- rep(1, length(p_grid))  # a prior which states for the probabilities in p_grid, one above 0.5 are equally likely, while below ore impossible
birth1_2 <- c(birth1, birth2)


for(i in seq(from = 10, to = length(birth1_2), by = 10)){
likelihood <- dbinom(sum(birth1_2[1:i]), 
                     size=length(birth1_2[1:i]), 
                     prob=p_grid ) # What is the likelihood of 8 outcomes from 15 samples given a probability of p_grid

posterior <- likelihood * prior  # "add" the likelihood to the prior to find the posterior
posterior <- posterior / sum(posterior) # normalise the posterior

if(i == 10){plot(x = p_grid, y = posterior, ylim = c(0,0.014))}
lines(x = p_grid, y = posterior, col = i/10)
}
abline(v = p_grid[which(posterior == max(posterior))])
text(x = 0, 
     y = 0.013, 
     paste("Parameter that maxes the posterior =",
           round(p_grid[which(posterior == max(posterior))],3)),
     cex = 0.8,
     pos = 4)
```
What we actually want here is the 
*As can be seen by the plot the more data maximises the probability. or* $n$

3H2. Using the sample function, draw 10,000 random parameter values from the posterior distribution
you calculated above. Use these samples to estimate the 50%, 89%, and 97% highest posterior
density intervals.

```{r}

samples <- sample(p_grid , prob=posterior , size=1e5 , replace=TRUE ) # sample from all the possible probabilities 10k times with the probabilities

HPDI(samples = samples, prob = 0.5)
HPDI(samples = samples, prob = 0.89)
HPDI(samples = samples, prob = 0.97)
```


3H3. Use rbinom to simulate 10,000 replicates of 200 births. You should end up with 10,000 numbers,
each one a count of boys out of 200 births. Compare the distribution of predicted numbers
of boys to the actual count in the data (111 boys out of 200 births). There are many good ways to
visualize the simulations, but the dens command (part of the rethinking package) is probably the
easiest way in this case. Does it look like the model fits the data well? That is, does the distribution
of predictions include the actual observation as a central, likely outcome?

```{r}
simulat1e1 <- rbinom(1e5, size = 200, prob = samples)

dens_3H3 <- dens(simulat1e1, xlim = c(0,200), adj = 1)
abline(v= 111)
```


3H4. Now compare 10,000 counts of boys from 100 simulated first borns only to the number of boys in the first births, birth1. How does the model look in this light?

```{r}
likelihood <- 
   dbinom(sum(birth1), 
          size=length(birth1), 
          prob=p_grid ) # What is the likelihood of 8 outcomes from 15 samples given a probability of p_grid

posterior <- 
   likelihood * prior  # "add" the likelihood to the prior to find the posterior

posterior <- 
   posterior / 
   sum(posterior) # normalise the posterior

samples_3H4 <- 
   sample(p_grid, 
          size = 1e5,
          prob = posterior, 
          replace = TRUE)

sim_3H4 <- 
   rbinom(1e5, 
          size = 100, 
          prob = samples_3H4)


dens_3H3 <- dens(simulat1e1, xlim = c(0,200), adj = 1)
dens_3H4 <- dens(sim_3H4, add = TRUE, col = "darkblue", adj = 1)
abline(v = sum(birth1), 
       col = "darkblue")
```


3H5. The model assumes that sex of first and second births are independent. To check this assumption,
focus now on second births that followed female first borns. Compare 10,000 simulated counts
of boys to only those second births that followed girls. To do this correctly, you need to count the
number of first borns who were girls and simulate that many births, 10,000 times. Compare the
counts of boys in your simulations to the actual observed count of boys following girls. How does the
model look in this light? Any guesses what is going on in these data?

*First we need to count all the girl-boy (0-1) and girl-girl (0-0); Then allocate a binomial to the options, all first born boys will be removed* 

```{r}
birth_dat <- 
   data.frame(birth1,
              birth2)

birth_dat <- 
   birth_dat %>%
   mutate(GB = case_when(
      birth1 == 0 &
         birth2 == 1 ~ 1,
      TRUE ~ 0
      ))%>%
   mutate(GG = case_when(
      birth1 == 0 &
         birth2 == 0 ~ 1,
      TRUE ~ 0
      ))
head(birth_dat)
```


```{r}
likelihood_3H5_GB <- 
   dbinom(sum(birth_dat$GB), 
          size=nrow(birth_dat), 
          prob=p_grid ) # What is the likelihood of 8 outcomes from 15 samples given a probability of p_grid

posterior_3H5_GB <- 
   likelihood_3H5_GB * prior  # "add" the likelihood to the prior to find the posterior

posterior_3H5_GB <- 
   posterior_3H5_GB / 
   sum(posterior_3H5_GB) # normalise the posterior

samples_3H5_GB <- 
   sample(p_grid, 
          size = 1e5,
          prob = posterior_3H5_GB, 
          replace = TRUE)

sim_3H5_GB <- 
   rbinom(1e5, 
          size = 100, 
          prob = samples_3H5_GB)

# now simulating for Girl girl
likelihood_3H5_GG <- 
   dbinom(sum(birth_dat$GG), 
          size=nrow(birth_dat), 
          prob=p_grid ) # What is the likelihood of 8 outcomes from 15 samples given a probability of p_grid

posterior_3H5_GG <- 
   likelihood_3H5_GG * prior  # "add" the likelihood to the prior to find the posterior

posterior_3H5_GG <- 
   posterior_3H5_GG / 
   sum(posterior_3H5_GG) # normalise the posterior

samples_3H5_GG <- 
   sample(p_grid, 
          size = 1e5,
          prob = posterior_3H5_GG, 
          replace = TRUE)

sim_3H5_GG <- 
   rbinom(1e5, 
          size = 100, 
          prob = samples_3H5_GG)



dens_3H4 <- dens(sim_3H5_GB, xlim = c(0,100), ylim = c(0,0.07), adj = 1)
dens_3H5 <- dens(sim_3H5_GG, add = TRUE,  col = "darkblue", adj = 1)
abline(v = sum(birth_dat$GB))
abline(v = sum(birth_dat$GG),  col = "darkblue")

```

These probability distributions are very different and infer that the sex of the second child might be conditional of the sex of the first. If we expect the sex at birth to be independent then we would expect both probability distributions to be centered around 25/100.


